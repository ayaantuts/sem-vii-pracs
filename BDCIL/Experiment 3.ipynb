{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742353e7",
      "metadata": {
        "id": "742353e7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Link is https://github.com/Engg-Abhinav/Feature-Engineering/blob/main/blackFriday_train.csv\n",
        "import os\n",
        "import urllib\n",
        "def fetch_dataset(link=\"https://raw.githubusercontent.com/Engg-Abhinav/Feature-Engineering/refs/heads/main/blackFriday_train.csv\", name=\"blackfriday_train.csv\"):\n",
        "\ttarget_dir = os.path.join(\"data\")\n",
        "\tos.makedirs(target_dir, exist_ok=True)\n",
        "\ttarget_file = os.path.join(target_dir, name)\n",
        "\tif not os.path.exists(target_file):\n",
        "\t\tprint(f\"Downloading {name} from {link}...\")\n",
        "\t\turllib.request.urlretrieve(link, target_file)\n",
        "\t\tprint(f\"File saved to {target_file}\")\n",
        "\telse:\n",
        "\t\tprint(f\"{name} already exists in {target_dir}, skipping download.\")\n",
        "fetch_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55768e2b",
      "metadata": {
        "id": "55768e2b"
      },
      "source": [
        "# Experiment 3 $-$ Dask Implementation\n",
        "## Section 1: Basic Dask Array Creation and Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c1395a",
      "metadata": {
        "id": "10c1395a"
      },
      "outputs": [],
      "source": [
        "import dask.array as da\n",
        "\n",
        "X = da.arange(101, chunks=5)\n",
        "print(X.compute())\n",
        "\n",
        "print(X.chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db3b160d",
      "metadata": {
        "id": "db3b160d"
      },
      "source": [
        "## Section 2: Convert NumPy array to Dask Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "422b98e9",
      "metadata": {
        "id": "422b98e9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X2 = np.arange(21)\n",
        "y = da.from_array(X2, chunks=5)\n",
        "\n",
        "result = y.compute() # result is stored in ndarray format\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf7ca004",
      "metadata": {
        "id": "bf7ca004"
      },
      "source": [
        "## Section 3: Calculate Mean of Large Array Using Dask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbd46c38",
      "metadata": {
        "id": "cbd46c38"
      },
      "outputs": [],
      "source": [
        "X3 = np.arange(1e5)\n",
        "y2 = da.from_array(X3, chunks=100)\n",
        "\n",
        "print(y2.mean().compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a904930a",
      "metadata": {
        "id": "a904930a"
      },
      "source": [
        "## Section 4: Reading CSV with Pandas vs Dask (Time comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f17908",
      "metadata": {
        "id": "f2f17908"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "%time temp = pd.read_csv(\"./data/blackfriday_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119887f9",
      "metadata": {
        "id": "119887f9"
      },
      "outputs": [],
      "source": [
        "import dask.dataframe as dd\n",
        "%time df = dd.read_csv(\"./data/blackfriday_train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7266ab6b",
      "metadata": {
        "id": "7266ab6b"
      },
      "source": [
        "## Section 5: Dask Dataframe Basic Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580fadbc",
      "metadata": {
        "id": "580fadbc"
      },
      "outputs": [],
      "source": [
        "df.Gender.value_counts().compute() # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8abeae27",
      "metadata": {
        "id": "8abeae27"
      },
      "outputs": [],
      "source": [
        "df.groupby(df.Gender).Purchase.max().compute() # type: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ccd312",
      "metadata": {
        "id": "b2ccd312"
      },
      "source": [
        "## Section 6: Setup Dask ML with Parallel Backend for Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "079971de",
      "metadata": {
        "id": "079971de"
      },
      "outputs": [],
      "source": [
        "from dask.distributed import Client\n",
        "client = Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd7f449e",
      "metadata": {
        "id": "bd7f449e"
      },
      "outputs": [],
      "source": [
        "from joblib import parallel_backend\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# client = Client() # commented because already a client is running\n",
        "print(\"Dashboard:\", client.dashboard_link)\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "with parallel_backend('dask'):\n",
        "    model = RandomForestClassifier(verbose=2, n_jobs=-1, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model trained successfully!\")\n",
        "print(\"Accuracy: \", model.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e8ee08d",
      "metadata": {
        "id": "6e8ee08d"
      },
      "source": [
        "## Section 7: Dask ML Native Algorithms Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26962fe6",
      "metadata": {
        "id": "26962fe6"
      },
      "outputs": [],
      "source": [
        "from dask_ml.linear_model import LogisticRegression\n",
        "from dask_ml.preprocessing import OneHotEncoder\n",
        "from dask_ml.cluster import KMeans\n",
        "\n",
        "# client = Client() # already in use\n",
        "print(\"Dashboard:\", client.dashboard_link)\n",
        "\n",
        "X = da.random.random((10000, 20), chunks=(1000, 20))\n",
        "y = da.random.randint(0, 2, size=(10000,), chunks=(1000,))\n",
        "\n",
        "print(\"\\n--- Logistic Regression ---\")\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X, y)\n",
        "print(\"Logistic Regression coefficients shape:\", log_reg.coef_.shape)\n",
        "\n",
        "print(\"\\n--- One Hot Encoder ---\")\n",
        "cat_data = da.random.randint(0, 5, size=(10000, 3), chunks=(1000, 3))\n",
        "encoder = OneHotEncoder(sparse_output=True)\n",
        "encoder_result = encoder.fit_transform(cat_data)\n",
        "print(\"Encoded shape:\", encoder_result.shape)\n",
        "\n",
        "print(\"\\n--- KMeans ---\")\n",
        "kmeans = KMeans(n_clusters=5, init_max_iter=5, random_state=42)\n",
        "kmeans.fit(X)\n",
        "print(\"KMeans cluster centers shape:\", kmeans.cluster_centers_.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebba6c34",
      "metadata": {
        "id": "ebba6c34"
      },
      "source": [
        "## Section 8: Full Example: Dask DataFrame to ML Pipeline on Black Friday Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask-ml"
      ],
      "metadata": {
        "id": "bgGad8f760Lc"
      },
      "id": "bgGad8f760Lc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dee34b0",
      "metadata": {
        "id": "4dee34b0"
      },
      "outputs": [],
      "source": [
        "# Starts a Dask client and displays the dashboard link for real-time monitoring\n",
        "from dask.distributed import Client\n",
        "\n",
        "client2 = Client()\n",
        "print(\"Dashboard link for section 8:\", client2.dashboard_link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72bf709b",
      "metadata": {
        "id": "72bf709b"
      },
      "outputs": [],
      "source": [
        "# Loads the Black Friday dataset with Dask DataFrame for scalable handling of large CSV files.\n",
        "from dask import dataframe as dd\n",
        "\n",
        "df = dd.read_csv(\"./data/blackfriday_train.csv\")\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "df.describe().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f14ece",
      "metadata": {
        "id": "69f14ece"
      },
      "outputs": [],
      "source": [
        "# Checks and fills missing values in specific columns.\n",
        "# Checking for missing values in the dataset\n",
        "missing_values = df.isnull().sum().compute()\n",
        "print(\"Missing values in each column:\\n\", missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d133310",
      "metadata": {
        "id": "3d133310"
      },
      "outputs": [],
      "source": [
        "# Filling missing values in features Product_Category_2, Product_Category_3\n",
        "df['Product_Category_2'] = df['Product_Category_2'].fillna(df['Product_Category_2'].mean())\n",
        "df['Product_Category_3'] = df['Product_Category_3'].fillna(df['Product_Category_3'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ca472d",
      "metadata": {
        "id": "22ca472d"
      },
      "outputs": [],
      "source": [
        "# Converts categorical columns into categorical type, then codes them into integers for ML compatibility.\n",
        "print(df.City_Category.value_counts().compute())\n",
        "print(df.Stay_In_Current_City_Years.value_counts().compute())\n",
        "print(df.Age.value_counts().compute())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f93bc3",
      "metadata": {
        "id": "a0f93bc3"
      },
      "outputs": [],
      "source": [
        "# Convert these columns to category type\n",
        "df = df.categorize(columns=['City_Category', 'Stay_In_Current_City_Years']).persist()\n",
        "\n",
        "# Code them into integers\n",
        "from dask_ml.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=True)\n",
        "encoded_city = encoder.fit_transform(df[['City_Category']])\n",
        "encoded_stay = encoder.fit_transform(df[['Stay_In_Current_City_Years']])\n",
        "age_map = {\n",
        "    '0-17': 8.5,\n",
        "    '18-25': 21.5,\n",
        "    '26-35': 30.5,\n",
        "    '36-45': 40.5,\n",
        "    '46-50': 48,\n",
        "    '51-55': 53,\n",
        "    '55+': 60\n",
        "}\n",
        "df['Age'] = df['Age'].map(age_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d37629",
      "metadata": {
        "id": "52d37629"
      },
      "outputs": [],
      "source": [
        "# Persists data in memory for faster repeated operations.\n",
        "df = df.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967cf653",
      "metadata": {
        "id": "967cf653"
      },
      "outputs": [],
      "source": [
        "# Splits data into train and test sets using Dask ML’s train_test_split.\n",
        "from dask_ml.model_selection import train_test_split\n",
        "\n",
        "# Features: numerical + encoded categoricals\n",
        "X = dd.concat([df[['User_ID', 'Age', 'Occupation', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3']],\n",
        "\t\t\t   encoded_city, encoded_stay], axis=1)  # Features\n",
        "y = df['Purchase']  # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65952c05",
      "metadata": {
        "id": "65952c05"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.persist()\n",
        "X_test = X_test.persist()\n",
        "y_train = y_train.persist()\n",
        "y_test = y_test.persist()\n",
        "# Converts dataframes to Dask arrays for compatibility with Dask ML models.\n",
        "X_train = X_train.to_dask_array(lengths=True)\n",
        "X_test = X_test.to_dask_array(lengths=True)\n",
        "y_train = y_train.to_dask_array(lengths=True)\n",
        "y_test = y_test.to_dask_array(lengths=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "029f6753",
      "metadata": {
        "id": "029f6753"
      },
      "outputs": [],
      "source": [
        "# Trains a Linear Regression model using Dask ML.\n",
        "from dask_ml.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bfb6dc7",
      "metadata": {
        "id": "9bfb6dc7"
      },
      "outputs": [],
      "source": [
        "# Makes predictions and computes R² score using sklearn metrics on computed numpy arrays.\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "y_pred = model.predict(X_test).compute()\n",
        "score = r2_score(y_test.compute(), y_pred)\n",
        "print(\"R² score:\", score)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "bdcil",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}