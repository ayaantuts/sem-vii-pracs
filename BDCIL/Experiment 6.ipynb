{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I06WcIQ7JRFy"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sample code to implement Spark Context\n",
        "from pyspark import SparkContext\n",
        "\n",
        "sc = SparkContext(\"local\", \"RDD Example\")\n",
        "\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "rdd = sc.parallelize(numbers)\n",
        "\n",
        "squared_rdd = rdd.map(lambda x: x**2)\n",
        "filtered_rdd = squared_rdd.filter(lambda x: x > 10)\n",
        "\n",
        "result = filtered_rdd.collect()\n",
        "print(result)"
      ],
      "metadata": {
        "id": "wDU4ZGZ7NXc5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialise SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "import json, re\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "            .appName(\"WordCount\") \\\n",
        "            .master(\"local[*]\") \\\n",
        "            .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "N3sODa1GNwt3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Creating input files\n",
        "# Word Count input\n",
        "with open(\"input.txt\", \"w\") as f:\n",
        "    f.write(\"hello world\\nhello spark\\nhello pyspark world\")\n",
        "\n",
        "# CSV files (users & purchases)\n",
        "with open(\"users.csv\", \"w\") as f:\n",
        "    f.write(\"user_id,name\\n1,Alice\\n2,Bob\\n3,Charlie\")\n",
        "\n",
        "with open(\"purchases.csv\", \"w\") as f:\n",
        "    f.write(\"user_id,product,amount\\n1,Book,100.0\\n2,Laptop,800.5\\n1,Pen,50.0\\n3,Phone,200.0\")\n",
        "\n",
        "# JSON file\n",
        "with open(\"people.json\", \"w\") as f:\n",
        "    f.write('{\"name\": \"Alice\", \"age\": 30}\\n')\n",
        "    f.write('{\"name\": \"Bob\", \"age\": 40}\\n')\n",
        "    f.write('{\"name\": \"Eve\", \"age\": 29}\\n')\n",
        "    f.write('{\"name\": \"Charlie\", \"age\": 40}\\n')\n",
        "\n",
        "# Apache log file\n",
        "with open(\"apache.access.log\", \"w\") as f:\n",
        "    f.write('127.0.0.1 - - [10/Oct/2000:13:55:36 -0700] \"GET /index.html HTTP/1.0\" 200 2326\\n')\n",
        "    f.write('127.0.0.1 - - [10/Oct/2000:13:55:56 -0700] \"GET /products HTTP/1.0\" 200 1234\\n')\n",
        "    f.write('127.0.0.1 - - [10/Oct/2000:13:56:01 -0700] \"GET /index.html HTTP/1.0\" 200 2326\\n')\n",
        "    f.write('127.0.0.1 - - [10/Oct/2000:13:56:16 -0700] \"GET /login HTTP/1.0\" 200 543\\n')\n",
        "    f.write('127.0.0.1 - - [10/Oct/2000:13:56:36 -0700] \"GET /index.html HTTP/1.0\" 200 2326\\n')\n",
        "    f.write('127.0.0.1 - - [10/Oct/2000:13:56:56 -0700] \"GET /products HTTP/1.0\" 200 1234\\n')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L8bhki3wSy3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6.1 - Word Count (RDD)\n",
        "print(\"\\n=== Word Count (RDD) ===\")\n",
        "text_file = sc.textFile(\"input.txt\")\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "                  .map(lambda word: (word, 1)) \\\n",
        "                  .reduceByKey(lambda a, b: a + b)\n",
        "print(counts.collect())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M0uaWoPYWaDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6.2 â€” CSV Join & Aggregation (RDD)\n",
        "print(\"\\n=== CSV Join & Aggregation (RDD) ===\")\n",
        "purchases = sc.textFile(\"purchases.csv\")\n",
        "header = purchases.first()\n",
        "purchasesRDD = purchases.filter(lambda line: line != header) \\\n",
        "                        .map(lambda line: line.split(\",\")) \\\n",
        "                        .map(lambda cols: (cols[0], float(cols[2])))\n",
        "users = sc.textFile(\"users.csv\")\n",
        "header2 = users.first()\n",
        "usersRDD = users.filter(lambda line: line != header2) \\\n",
        "                .map(lambda line: line.split(\",\")) \\\n",
        "                .map(lambda cols: (cols[0], cols[1]))\n",
        "\n",
        "joinedRDD = usersRDD.join(purchasesRDD)  # (user_id, (name, amount))\n",
        "totalByUser = joinedRDD.map(lambda x: (x[1][0], x[1][1])) \\\n",
        "                       .reduceByKey(lambda a, b: a + b)\n",
        "print(totalByUser.collect())"
      ],
      "metadata": {
        "id": "DLGHtt6UWgQq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6.3 - JSONL processing (RDD)\n",
        "print(\"\\n=== JSON Processing (RDD) ===\")\n",
        "logs = sc.textFile(\"people.json\")\n",
        "eventsRDD = logs.map(lambda line: json.loads(line)) \\\n",
        "                .map(lambda rec: (rec[\"age\"], 1)) \\\n",
        "                .reduceByKey(lambda a, b: a + b)\n",
        "print(eventsRDD.collect())\n",
        "# sc.stop()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4Wh3_pmZWmjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 6.4 - Apache Log parsing (RDD)\n",
        "print(\"\\n=== Apache Log Parsing (RDD) ===\")\n",
        "log_pattern = '^(\\S+) (\\S+) (\\S+) \\[(.*?)\\] \"(.*?)\" (\\S+) (\\S+)$'\n",
        "regex = re.compile(log_pattern)\n",
        "\n",
        "logs = sc.textFile(\"apache.access.log\")\n",
        "logsRDD = logs.map(lambda line: regex.match(line)) \\\n",
        "              .filter(lambda m: m is not None) \\\n",
        "              .map(lambda m: (m.group(5).split(\" \")[1], 1)) \\\n",
        "              .reduceByKey(lambda a, b: a + b)\n",
        "print(logsRDD.collect())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eTvdWDc7WtPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. Modify WordCount to remove stopwords and show top-10 meaningful words.\n",
        "print(\"=== Modified Word Count(RDD) ===\")\n",
        "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
        "\n",
        "# Write WordCount here\n",
        "counts_ex = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "                     .filter(lambda word: word not in stopwords) \\\n",
        "                     .map(lambda word: (word, 1)) \\\n",
        "                     .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "print(counts_ex.takeOrdered(10, key=lambda x: -x[1]))"
      ],
      "metadata": {
        "id": "Ki5wwoPNWxyo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Change join to handle missing IDs (leftOuterJoin) and show names with zero purchases.\n",
        "print(\"=== Modified Join (RDD) ===\")\n",
        "\n",
        "# Write Join here\n",
        "purchases = sc.textFile(\"purchases.csv\")\n",
        "header = purchases.first()\n",
        "purchasesRDD = purchases.filter(lambda line: line != header) \\\n",
        "                        .map(lambda line: line.split(\",\")) \\\n",
        "                        .map(lambda cols: (cols[0], float(cols[2])))\n",
        "users = sc.textFile(\"users.csv\")\n",
        "header2 = users.first()\n",
        "usersRDD = users.filter(lambda line: line != header2) \\\n",
        "                .map(lambda line: line.split(\",\")) \\\n",
        "                .map(lambda cols: (cols[0], cols[1]))\n",
        "\n",
        "joinedRDD = usersRDD.leftOuterJoin(purchasesRDD)  # (user_id, (name, amount))\n",
        "totalByUser = joinedRDD.map(lambda x: (x[1][0], x[1][1])) \\\n",
        "                       .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "print(totalByUser.collect())"
      ],
      "metadata": {
        "id": "Y1NxlADdeyAv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Use mapPartitions to simulate expensive init (e.g., a fake model) and measure runtime difference.\n",
        "print(\"=== MapPartitions (RDD) ===\")\n",
        "\n",
        "# Write MapPartitions here\n",
        "import time\n",
        "\n",
        "def process_partition(iterator):\n",
        "    # Simulate an expensive initialization per partition\n",
        "    time.sleep(1)\n",
        "    initialized_value = \"Initialized\"\n",
        "    results = []\n",
        "    for x in iterator:\n",
        "        results.append(f\"{initialized_value}: {x * 2}\")\n",
        "    return results\n",
        "\n",
        "# Create a simple RDD\n",
        "data = sc.parallelize(range(10))\n",
        "\n",
        "# Apply mapPartitions\n",
        "start_time = time.time()\n",
        "processed_rdd = data.mapPartitions(process_partition)\n",
        "result = processed_rdd.collect()\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Result: {result}\")\n",
        "print(f\"Runtime with mapPartitions: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Compare with map (which would initialize for each element)\n",
        "def process_element(x):\n",
        "    # Simulate an expensive initialization per element\n",
        "    time.sleep(0.1)\n",
        "    initialized_value = \"Initialized\"\n",
        "    return f\"{initialized_value}: {x * 2}\"\n",
        "\n",
        "start_time_map = time.time()\n",
        "processed_rdd_map = data.map(process_element)\n",
        "result_map = processed_rdd_map.collect()\n",
        "end_time_map = time.time()\n",
        "\n",
        "print(f\"Runtime with map: {end_time_map - start_time_map:.2f} seconds\")"
      ],
      "metadata": {
        "id": "Tj01EPAAhe9J",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}