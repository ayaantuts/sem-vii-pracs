{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "46faad59",
      "metadata": {
        "id": "46faad59"
      },
      "source": [
        "# Experiment 2\n",
        "## Perform Preprocessing steps in NLP.\n",
        "_Sub-objectives_\n",
        "1. Apply basic preprocessing: tokenization, stopword removal, etc.\n",
        "2. Understand the importance of text normalization.\n",
        "3. Compare NLP preprocessing tools (e.g., NLTK, spaCy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46edcacf",
      "metadata": {
        "id": "46edcacf"
      },
      "outputs": [],
      "source": [
        "text = \"Natural Language Processing (NLP) enables computers to understand human language. It's fascinating!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b774b9b",
      "metadata": {
        "id": "9b774b9b"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk spacy\n",
        "# !python -m spacy download en_core_web_sm\n",
        "# !pip install indic-nlp-library\n",
        "# !pip install nltk\n",
        "# !pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458bd24d",
      "metadata": {
        "id": "458bd24d"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Lowercase\n",
        "text = text.lower()\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Remove punctuation\n",
        "tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "# Stopword removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "print(\"NLTK Tokens:\", lemmatized_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5523ab5f",
      "metadata": {
        "id": "5523ab5f"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Load English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Apply preprocessing\n",
        "doc = nlp(text.lower())\n",
        "\n",
        "# Filter tokens\n",
        "tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "print(\"spaCy Tokens:\", tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8d7ca65",
      "metadata": {
        "id": "b8d7ca65"
      },
      "outputs": [],
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# Sample Marathi text\n",
        "text = \"नैसर्गिक भाषा प्रक्रिया संगणकांना मानवी भाषा समजावून देण्याची क्षमता देते.\"\n",
        "\n",
        "# Tokenization using Indic NLP\n",
        "tokens = indic_tokenize.trivial_tokenize(text)\n",
        "\n",
        "# Define Marathi stopwords (You may create or find a list)\n",
        "marathi_stopwords = set([\n",
        "    'आणि', 'होते', 'तो', 'ती', 'ते', 'ची', 'च्या', 'करून', 'आहे', 'या', 'असणे', 'साठी', 'म्हणून'\n",
        "])\n",
        "\n",
        "# Remove punctuation\n",
        "tokens = [word for word in tokens if word not in string.punctuation]\n",
        "\n",
        "# Remove stopwords\n",
        "filtered_tokens = [word for word in tokens if word not in marathi_stopwords]\n",
        "\n",
        "print(\"Tokens after stopword removal:\", filtered_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25152b78",
      "metadata": {
        "id": "25152b78"
      },
      "outputs": [],
      "source": [
        "import stanza\n",
        "\n",
        "stanza.download('mr')  # Marathi model\n",
        "nlp = stanza.Pipeline('mr')\n",
        "\n",
        "text = \"नैसर्गिक भाषा प्रक्रिया संगणकांना मानवी भाषा समजावून देण्याची क्षमता देते.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for sentence in doc.sentences:\n",
        "    for word in sentence.words:\n",
        "        print(f\"Word: {word.text}\\tLemma: {word.lemma}\\tPOS: {word.upos}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}